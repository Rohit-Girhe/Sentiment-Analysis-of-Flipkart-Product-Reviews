{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cf1d912",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Basic Data Handling\n",
    "import pandas as pd  ## Handling Datasets (Like CSVs, Excel, Json, etc.,)\n",
    "import numpy as np  ## For numrical operations and arrays\n",
    "\n",
    "## Text Preprocessing\n",
    "import re   ## For regex operations for cleaning text\n",
    "import string  ## For Punctuation Handling\n",
    "import nltk  ## Natural Language ToolKit (For stopwords, stemming etc)\n",
    "from nltk.corpus import stopwords  ## To remove common, meaningless words\n",
    "from nltk.stem import PorterStemmer ## For Stemming\n",
    "from nltk.stem import WordNetLemmatizer  ## For Lemmatizations\n",
    "\n",
    "## Sklearn feature exractions (Data Transformation Model)\n",
    "from sklearn.feature_extraction.text import CountVectorizer  ## BAg of Words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  ## TF-IDF Model\n",
    "\n",
    "## Data Preprocessing and Model Building\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB  ## Classifier for text data\n",
    "from sklearn.linear_model import LogisticRegression  ## Another good text classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "## Model Evaluation\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "## Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## Progress Bar for Loops and apply \n",
    "from tqdm import tqdm  ## To visually track long operations\n",
    "tqdm.pandas()  ## Enabled progress_apply() in pandas\n",
    "\n",
    "## Download nltk resources (only need to do once)\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')  ## for lemmatizer\n",
    "# nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c77fefca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\rohit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "357e357d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rohit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7a6bb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\rohit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add project root (parent of Notebook/) to Python path\n",
    "project_root = os.path.abspath(\"..\")\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from src.text_preprocessing import preprocess_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7e8b4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: ..\\Data\\data_cleaned.csv\n",
      "Shape: (8510, 9)\n",
      "\n",
      "Sample cleaned texts:\n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                         Review text                                                                                                                                                                         cleaned_review\n",
      "                                                                                                                                                                                        Nice product, good quality, but price is now rising which is a bad sign. 800-850 was an affordable price, especially when we play everyday. So kindly help us out in terms of the price. Thank You.READ MORE                                                       nice product good quality price rising bad sign affordable price especially play everyday kindly help u term price thank youread\n",
      "                                                                                                                                                                                                                                                                              They didn't supplied Yonex Mavis 350. Outside cover was Yonex Ad inside was a cheapest....  Sad to hear this.READ MORE                                                                                                    didnt supplied yonex mavis outside cover yonex ad inside cheapest sad hear thisread\n",
      "                                                                                                                                                                                                                                       Worst product. Damaged shuttlecocks packed in new box. It's not a original yonex product. Don't buy.flipkart platform is chosen to fraud the buyers.READ MORE                                                              worst product damaged shuttlecock packed new box original yonex product dont buyflipkart platform chosen fraud buyersread\n",
      "Quite O. K. , but nowadays  the quality of the corks like not as before 3 to 5 years back.. I am using MAVIS 350 for more than 15 years quality of corks was very very good at that times, but now I am not getting the quality corks as like before, rate of corks also too much now, I am  very sorry to say like this, but in my experience , my Statment is very true to   my knowledgeREAD MORE quite nowadays quality cork like year back using mavis year quality cork good time getting quality cork like rate cork also much sorry say like experience statment true knowledgeread\n",
      "                                                                                                                                                                                                                                                                                  Over pricedJust â?¹620 ..from retailer.I didn't understand.. Wat is d advantage of buying dis frm flipkrtREAD MORE                                                                                                      pricedjust â¹ retaileri didnt understand wat advantage buying dis frm flipkrtread\n"
     ]
    }
   ],
   "source": [
    "# Load data and apply preprocessing\n",
    "import os\n",
    "# from src.text_preprocessing import preprocess_corpus\n",
    "\n",
    "# TODO: Update the file name and column name below to match your dataset\n",
    "# Example assumes a CSV in the `Data` folder with a text column named 'Review'\n",
    "\n",
    "import os\n",
    "\n",
    "# Correct path from Notebook/ to Data/\n",
    "data_path = os.path.join(\"..\", \"Data\", \"data_cleaned.csv\")  # or \"data.csv\"\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "print(\"Loaded:\", data_path)\n",
    "print(\"Shape:\", df.shape)\n",
    "\n",
    "# Replace 'Review' with the actual text column name containing the review text\n",
    "text_column = \"Review text\"  # e.g., 'Review', 'Review_Text', 'review'\n",
    "\n",
    "# Apply preprocessing to create a new cleaned text column\n",
    "df[\"cleaned_review\"] = preprocess_corpus(df[text_column])\n",
    "\n",
    "# Quick check of before vs after\n",
    "print(\"\\nSample cleaned texts:\\n\")\n",
    "print(\n",
    "    df[[text_column, \"cleaned_review\"]]\n",
    "    .head(5)\n",
    "    .to_string(index=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "126aff24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6421856639247944\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.54      0.56       153\n",
      "           2       0.31      0.07      0.11        61\n",
      "           3       0.56      0.08      0.14       123\n",
      "           4       0.20      0.02      0.03       349\n",
      "           5       0.66      0.98      0.79      1016\n",
      "\n",
      "    accuracy                           0.64      1702\n",
      "   macro avg       0.46      0.34      0.33      1702\n",
      "weighted avg       0.54      0.64      0.54      1702\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 82   3   1   4  63]\n",
      " [ 24   4   0   1  32]\n",
      " [ 18   2  10   6  87]\n",
      " [ 10   1   2   6 330]\n",
      " [  4   3   5  13 991]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "X = df[\"cleaned_review\"]\n",
    "y = df[\"Ratings\"]          # target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751567c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenve",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
